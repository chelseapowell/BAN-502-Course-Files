---
output:
  word_document: default
  html_document: default
---
#BAN 502: Module 3 Assignment 2
##Logistic Regression (classification)
###Chelsea Powell

```{r}
library(tidyverse)
library(MASS)
library(caret)
#install.packages("ROCR")
library(ROCR)
```

```{r}
library(readr)
parole <- read_csv("parole.csv")
View(parole)

str(parole)
summary(parole)
```

```{r}
parole = parole %>% mutate(male = as.factor(male)) %>% 
  mutate(male = fct_recode(male, "female" = "0", "male" = "1" )) %>%
  mutate(race = as.factor(race)) %>% mutate(race = as.factor(race)) %>%
  mutate(race = fct_recode(race, "white" = "1", "other" = "2" )) %>%
  mutate(state = as.factor(state)) %>%
  mutate(state = fct_recode(state, "Other" = "1", "Kentucky" = "2", "Louisiana" = "3", "Virginia" = "4" )) %>%
  mutate(crime = as.factor(crime)) %>% 
  mutate(crime = fct_recode(crime, "Other" = "1", "Larceny" = "2", "Drug" = "3", "Driving" = "4" )) %>%
  mutate(multiple.offenses = as.factor(multiple.offenses)) %>% 
  mutate(multiple.offenses = fct_recode(multiple.offenses, "Single Offense" = "0", "Multiple Offenses" = "1" )) %>%
  mutate(violator = as.factor(violator)) %>% 
  mutate(violator = fct_recode(violator, "completed" = "0", "violated" = "1" ))
str(parole)
```

```{r}
set.seed(12345)
train.rows = createDataPartition(y = parole$violator, p=0.7, list = FALSE) #70% in training
train = parole[train.rows,] 
test = parole[-train.rows,]
```

```{r}
ggplot(parole, aes(x=male, fill=violator)) + geom_bar()
```
Males tend to violate their parole more than females based on the data.

```{r}
ggplot(parole, aes(x=race, fill=violator)) + geom_bar()
```
This looks almost even. There are more white criminals but less of them violate their parole.

```{r}
ggplot(parole, aes(x=violator, y=age)) + geom_boxplot()
```
The age of the person is higher if they complete their parole.

```{r}
ggplot(parole, aes(x=state, fill=violator)) + geom_bar()
```
This barplot shows that although there aren't as many people in Louisiana almost half of them violate their parole.

```{r}
ggplot(parole, aes(x=violator, y=max.sentence)) + geom_boxplot()
```
The lower people with setenced crimes violate their paroles.

```{r}
ggplot(parole, aes(x=multiple.offenses, fill=violator)) + geom_bar()
```
Multiple offense people violate their parole compared to single offense people.

```{r}
ggplot(parole, aes(x=crime, fill=violator)) + geom_bar()
```
Other crimes have a praole that is more often violated than larceny, drug, and driving crimes.

```{r}
mod1 = glm(violator ~ multiple.offenses , parole, family = "binomial")
summary(mod1)
```
The AIC of this model is 479.81. I'm not sure yet if that is a good number or not. I will find out in our stepwise regressions. It looks like if a person has multiple offenses then they are more likely to violate their parole.

```{r}
allmod = glm(violator ~., train, family = "binomial") 
summary(allmod)  
  
emptymod = glm(violator~1, train, family = "binomial")  
summary(emptymod)
```

```{r}
#backward
backmod = stepAIC(allmod, direction = "backward", trace = TRUE) 
summary(backmod)
```

Forward stepwise 
```{r}
#forward
forwardmod = stepAIC(emptymod, direction = "forward", scope=list(upper=allmod,lower=emptymod), trace = TRUE) 
summary(forwardmod) 
```
I ran both a forward and backward regression model to see if they came up with different models. They created the same models that have an AIC of 252.28 which is lower, and better, than my previous model with just violator and multiple offenses. The model that I have chosen includes violator, state, multiple offenses, race, age, and the maximum sentence. The most signficant variables are race, multiple offenses, and state.

```{r}
mod2 = glm(violator ~ multiple.offenses + state + race , parole, family = "binomial")
summary(mod2)
```
This model has an AIC of 365.26 which is lower than the model I chose above. This model is not as good as my previous model with more varaibles. Multiple offenses and the state of virginia are the most significant variables. The state of kentucky is not as valuable.

```{r}
newdata = data.frame(state = "Louisiana", multiple.offenses = "Multiple Offenses", race = "white")
predict(mod2, newdata, type="response")
```

```{r}
newdata1 = data.frame(state = "Kentucky", multiple.offenses = "Single Offense", race = "other")
predict(mod2, newdata1, type="response")
```

```{r}
predictions = predict(forwardmod, type="response")
head(predictions)
```

Threshold selection  
```{r}
#Change this next line to the names of your predictions and the response variable in the training data frame
ROCRpred = prediction(predictions,train$violator)

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
```
Area under the curve (AUC). AUC is a measure of the strength of the model. Values closer to 1 are better. Can be used to compare models.  
```{r}
as.numeric(performance(ROCRpred, "auc")@y.values)
```

```{r}
#Determine threshold to balance sensitivity and specificity
#DO NOT modify this code
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
```

```{r}
t1 = table(train$violator,predictions > 0.1455707)
t1
```
Calculate accuracy  
```{r}
(t1[1,1]+t1[2,2])/nrow(train)
```
Can apply trial and error to maximize accuracy (here trying 0.5 as threshold)
```{r}
t1 = table(train$violator,predictions > 0.4)
t1
(t1[1,1]+t1[2,2])/nrow(train)
```

```{r}
allmod1 = glm(violator ~., test, family = "binomial") 
summary(allmod1)  
  
emptymod1 = glm(violator~1, test, family = "binomial")  
summary(emptymod1)

forwardmod1 = stepAIC(emptymod1, direction = "forward", scope=list(upper=allmod,lower=emptymod), trace = TRUE) 
summary(forwardmod1)

predictionstest = predict(forwardmod1, type="response")
head(predictionstest)

test1 = table(test$violator,predictionstest > 0.4)
test1
(test1[1,1]+t1[2,2])/nrow(test1)
```















